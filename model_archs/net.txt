GDFHAT(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): Identity()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (1): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (2): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (3): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (4): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (5): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): GCA(
        (conv0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
        (conv_spatial): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=180)
        (conv1): Conv2d(180, 90, kernel_size=(1, 1), stride=(1, 1))
        (conv2): Conv2d(180, 90, kernel_size=(1, 1), stride=(1, 1))
        (conv_squeeze): Conv2d(2, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (conv): Conv2d(90, 180, kernel_size=(1, 1), stride=(1, 1))
      )
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (6): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (7): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (8): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (9): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (10): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
    (11): RTSG(
      (residual_group): AttenBlocks(
        (blocks): ModuleList(
          (0): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (1): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (2): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (3): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (4): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
          (5): GDFHAB(
            (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (attn): WindowAttention(
              (qkv): Linear(in_features=180, out_features=540, bias=True)
              (attn_drop): Dropout(p=0.0, inplace=False)
              (proj): Linear(in_features=180, out_features=180, bias=True)
              (proj_drop): Dropout(p=0.0, inplace=False)
              (softmax): Softmax(dim=-1)
            )
            (conv_block): TTSA(
              (qkv): Conv2d(180, 540, kernel_size=(1, 1), stride=(1, 1))
              (qkv_dwconv): Conv2d(540, 540, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=540)
              (project_out): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1))
              (attn_drop): Dropout(p=0.0, inplace=False)
            )
            (drop_path): DropPath()
            (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
            (GDFN): GDFMFL(
              (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
              (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
              (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
              (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
              (relu3): ReLU()
              (relu5): ReLU()
              (relu7): ReLU()
              (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
              (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            )
          )
        )
        (overlap_attn): GDFOCAB(
          (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (unfold): Unfold(kernel_size=(24, 24), dilation=1, padding=4, stride=16)
          (softmax): Softmax(dim=-1)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
          (GDFN): GDFMFL(
            (project_in_g): Conv2d(180, 956, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_in): Conv2d(180, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (dwconv_g): Conv2d(956, 956, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=956, bias=False)
            (dwconv3x3): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180, bias=False)
            (dwconv5x5): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=180, bias=False)
            (dwconv7x7): Conv2d(180, 180, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=180, bias=False)
            (relu3): ReLU()
            (relu5): ReLU()
            (relu7): ReLU()
            (project_out_g): Conv2d(956, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (project_out): Conv2d(540, 180, kernel_size=(1, 1), stride=(1, 1), bias=False)
          )
        )
      )
      (conv): GCA(
        (conv0): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=180)
        (conv_spatial): Conv2d(180, 180, kernel_size=(5, 5), stride=(1, 1), padding=(4, 4), dilation=(2, 2), groups=180)
        (conv1): Conv2d(180, 90, kernel_size=(1, 1), stride=(1, 1))
        (conv2): Conv2d(180, 90, kernel_size=(1, 1), stride=(1, 1))
        (conv_squeeze): Conv2d(2, 2, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3))
        (conv): Conv2d(90, 180, kernel_size=(1, 1), stride=(1, 1))
      )
      (patch_embed): PatchEmbed()
      (patch_unembed): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)